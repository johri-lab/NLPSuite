{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a31847e-525f-4cfa-bdb1-970aaf5feab1",
   "metadata": {},
   "source": [
    "# Large Langugage Model Inference\n",
    "- Once we have the text extracted from the table we infer the table using Large Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87648ee1",
   "metadata": {},
   "source": [
    "## Mistral Inference\n",
    "- Efficient for simple prompt\n",
    "- Limited capacity of handling prompt size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94059490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Users/johri/miniconda3/lib/python3.11/site-packages (0.3.3)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/johri/miniconda3/lib/python3.11/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /Users/johri/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/johri/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/johri/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.4)\n",
      "Requirement already satisfied: idna in /Users/johri/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/johri/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/johri/miniconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama.pull(\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171af6ef-e833-4ac3-adee-7e6dd8b42ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal \"ollama serve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b8a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Inference:\n",
      "  {\n",
      "       \"Table Interpretation\": {\n",
      "           \"Title\": \"Quarterly Sales Report\",\n",
      "           \"Structure\": \"A table with four columns: 'Product ID', 'Product Name', 'Region', and 'Sales Data'. The 'Sales Data' column is further nested, containing sub-columns 'Quarter', 'Units Sold', and 'Revenue ($)'.\",\n",
      "           \"Content Summary\": {\n",
      "               \"Data Points\": \"Three data points, each representing a product (Laptop Pro 15, Smartphone X, Tablet S), their region of sale, and quarterly sales data for each product.\",\n",
      "               \"Notable Columns\": [\"Product ID\", \"Product Name\", \"Region\", \"Quarter\", \"Units Sold\", \"Revenue ($)\"],\n",
      "               \"Trends\": \"Increasing trend in the number of units sold and revenue over the quarters for all products. The 'Laptop Pro 15' has the highest sales in terms of both units and revenue.\"\n",
      "           },\n",
      "           \"Relationships\": {\n",
      "               \"Columns Relation\": \"'Product ID' and 'Product Name' are related to the nested 'Sales Data'. The 'Region' column provides geographical context for the product sales.\",\n",
      "               \"Correlations or Hierarchies\": \"No clear correlations or hierarchies were found, but there is a trend of increasing sales over the quarters.\"\n",
      "           },\n",
      "           \"Metadata and Nested Structures\": {\n",
      "               \"Purpose\": \"The nested 'Sales Data' structure provides detailed quarterly sales information for each product.\",\n",
      "               \"Contribution to Context\": \"It enriches the table by offering a time-series analysis of the products' performance in different regions.\"\n",
      "           }\n",
      "       }\n",
      "   }\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "#    4. If there are positional markers or other structural metadata (like \"start_row\", \"end_row\", \"start_col\", \"end_col\"), explain how they contribute to understanding the tableâ€™s layout.\n",
    "    # 2. Identify the primary elements that represent rows, columns, and cell content. Explain what each element represents and how the table data is organized.\n",
    "\n",
    "def infer_table_with_ollama(table_json):\n",
    "    prompt_content = f\"\"\"\n",
    "                You are given a table represented in JSON format. Your task is to interpret the table, which may have varied structures and schemas.\n",
    "\n",
    "                Guidelines:\n",
    "                1. Analyze the table structure: Identify the columns, data types (numeric, categorical, text), and overall organization.\n",
    "                2. Summarize the key information: Describe the main content, highlight important columns, and identify any notable patterns or trends in the data.\n",
    "                3. Infer relationships: Explain how columns relate to each other, and if possible, identify any correlations or hierarchical information present.\n",
    "                4. Handle metadata and nested structures: If there is additional metadata or nested elements, infer their purpose and how they contribute to the table's context.\n",
    "\n",
    "                Here is the JSON table:\n",
    "\n",
    "                {json.dumps(table_json, indent=4)}\n",
    "\n",
    "                Provide a concise interpretation of the table, including its structure, content summary, and any relevant insights. The response should be formatted in JSON.\n",
    "            \"\"\"\n",
    "    \n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_content}\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(model=\"mistral\", messages=messages)\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "file_path = '/Users/johri/Projects/JnJ capstone/table detection/SciTSR/train/structure/0705.0450v1.4.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    table_json = json.load(file)\n",
    "    table_json = {\n",
    "  \"table\": {\n",
    "    \"title\": \"Quarterly Sales Report\",\n",
    "    \"columns\": [\"Product ID\", \"Product Name\", \"Region\", \"Sales Data\"],\n",
    "    \"data\": [\n",
    "      {\n",
    "        \"Product ID\": \"101\",\n",
    "        \"Product Name\": \"Laptop Pro 15\",\n",
    "        \"Region\": \"North America\",\n",
    "        \"Sales Data\": {\n",
    "          \"Quarter\": [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "          \"Units Sold\": [150, 200, 180, 220],\n",
    "          \"Revenue ($)\": [300000, 400000, 360000, 440000]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"Product ID\": \"102\",\n",
    "        \"Product Name\": \"Smartphone X\",\n",
    "        \"Region\": \"Europe\",\n",
    "        \"Sales Data\": {\n",
    "          \"Quarter\": [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "          \"Units Sold\": [500, 600, 550, 650],\n",
    "          \"Revenue ($)\": [250000, 300000, 275000, 325000]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"Product ID\": \"103\",\n",
    "        \"Product Name\": \"Tablet S\",\n",
    "        \"Region\": \"Asia\",\n",
    "        \"Sales Data\": {\n",
    "          \"Quarter\": [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "          \"Units Sold\": [300, 350, 330, 370],\n",
    "          \"Revenue ($)\": [150000, 175000, 165000, 185000]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "table_inference = infer_table_with_ollama(table_json)\n",
    "print(\"Table Inference:\\n\", table_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2941a73",
   "metadata": {},
   "source": [
    "## LLaMa3.2 Inference\n",
    "- Inferences from LLaMa was found to be more affective in identifying context\n",
    "- It handled the instructions of output format strictly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c90e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686a81d8-7bbb-440d-8327-f6892e599986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(prompt, model=\"llama3.2\", host=\"http://localhost:11434\"):\n",
    "    \n",
    "    url = f\"{host}/api/chat\"\n",
    "    \n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    data = json.dumps({\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"format\": \"json\",\n",
    "        \"options\": {\n",
    "            \"seed\": 42\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "\n",
    "    # print(response)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json() \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa84454d-5fc4-4033-8e37-b11519f46c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    ['Dat', 'ASCl', '', '', '', ''],\n",
    "    ['Method', 'LLM', 'SNLI', 'ANLI', 'CQA', 'SVAMP'],\n",
    "    ['STANDARD FINETUNING', 'NYA', '88.38', '43.58', '62.19', '62.63'],\n",
    "    ['DISTILLING STEP-BY-STEP', '20B', '89.12', '48.15', '63.25', '63.00'],\n",
    "    ['DISTILLING STEP-BY-STEP', '54OB', '89.51', '49.58', '63.29', '65.50']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c75375-3275-4465-978c-407dd808f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Extracted Text:\n",
    "Table 1: Distilling step-by-step works with different\n",
    "sizes of LLMs. When rationales are extracted from a\n",
    "20B GPT-NeoX model, Distilling step-by-step is still\n",
    "able to provide performance lift compared to standard\n",
    "finetuning on 220M TS models.\n",
    "\n",
    "Table 2: Our proposed multi-task training framework\n",
    "consistently leads to better performances than treating\n",
    "rationale and label predictions as a single task. Single-\n",
    "task training can at times lead to worse performance\n",
    "than standard finetuning.\n",
    "\n",
    " \n",
    "\n",
    "Dataset\n",
    "ANLI CQA  SVAMP\n",
    "\n",
    "STANDARD FINETUNING NIA 88.38 43.58 62.19 62.63\n",
    "DISTILLING STEP-BY-STEP 20B 89.12 48.15 63.25 63.00\n",
    "DISTILLING STEP-BY-STEP 540B 89.51 49.58 63.29 65.50\n",
    "\n",
    "Method LLM_se-SNLI\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "using the full dataset and thus requires larger model\n",
    "to close the performance gap.\n",
    "\n",
    "4.4 Further ablation studies\n",
    "\n",
    "So far, we have focused on showing the effective-\n",
    "ness of Distilling step-by-step on reducing the train-\n",
    "ing data required for finetuning or distilling smaller\n",
    "task-specific models. In this section, we perform\n",
    "further studies to understand the influence of dif-\n",
    "ferent components in the Distilling step-by-step\n",
    "framework. Specifically, we study (1) how differ-\n",
    "ent LLMs, from which the rationales are extracted,\n",
    "affect the effectiveness of Distilling step-by-step,\n",
    "and (2) how the multi-task training approach com-\n",
    "pares to other potential design choices in training\n",
    "small task-specific models with LLM rationales.\n",
    "Here, we fix the small task-specific models to be\n",
    "220M T5 models, and utilize 100% of the data on\n",
    "all datasets.\n",
    "\n",
    "Distilling step-by-step works with different sizes\n",
    "of decently trained LLMs. In addition to using\n",
    "540B PaLM as the LLM, here we consider a rela-\n",
    "tively smaller LLM, 20B GPT-NeoX model (Black\n",
    "et al., 2022), from which we extract rationales for\n",
    "Distilling step-by-step. In Table 1, we see that\n",
    "when coupled with LLMs of different sizes, Distill-\n",
    "ing step-by-step can still provide performance im-\n",
    "provements compared to standard finetuning. How-\n",
    "ever, the performance lift is smaller when rationales\n",
    "are extracted from the 20B GPT-NeoX model in-\n",
    "stead of from the 540B PaLM. This can be due\n",
    "to the fact that the larger PaLM model provides\n",
    "higher-quality rationales that are more beneficial\n",
    "for learning the task.\n",
    "\n",
    "Multi-task training is much more effective than\n",
    "single-task rationale and label joint prediction.\n",
    "There are different possible ways to train task-\n",
    "specific models with LLM-rationales as output su-\n",
    "pervisions. One straightforward approach is to con-\n",
    "catenate the rationale 7; and label ; into a single\n",
    "\n",
    " \n",
    "\n",
    "Dataset\n",
    "Method e-SNLI ANLI CQA SVAMP\n",
    "STANDARD FINETUNING = 88.38 = 43.58 62.19 62.63\n",
    "SINGLE-TASK TRAINING 88.88 = 43.50 61.37. 63.00\n",
    "MULTI-TASK TRAINING 89.51 49.58 63.29 65.50\n",
    "\n",
    " \n",
    "\n",
    "sequence [?;,9,] and treat the entire sequence as\n",
    "the target output in training small models, as con-\n",
    "sidered in (Magister et al., 2022; Ho et al., 2022):\n",
    "\n",
    "N\n",
    "Lengle = 57 LMF (esis). G)\n",
    "\n",
    "i=l\n",
    "\n",
    "In Table 2, we compare this single-task training\n",
    "approach to our proposed multi-task training ap-\n",
    "proach for utilizing LLM-rationales. We see that\n",
    "not only multi-task training consistently leads to\n",
    "better performance, single-task training with LLM-\n",
    "rationales can at times leads to worse performance\n",
    "than standard finetuning, e.g., on ANLI and CQA.\n",
    "In fact, similar results have also been observed\n",
    "in (Wiegreffe et al., 2021; Magister et al., 2022;\n",
    "Ho et al., 2022) that simply treating rationale and\n",
    "label predictions as a single joint task may harm the\n",
    "modelâ€™s performance on label prediction. This val-\n",
    "idates our use of the multi-task training approach,\n",
    "and highlights the need to treat the rationales care-\n",
    "fully so as to unleash their actual benefits.\n",
    "\n",
    "5 Discussion\n",
    "\n",
    "We propose Distilling step-by-step to extract ra-\n",
    "tionales from LLMs as informative supervision in\n",
    "training small task-specific models. We show that\n",
    "Distilling step-by-step reduces the training dataset\n",
    "required to curate task-specific smaller models; it\n",
    "also reduces the model size required to achieve,\n",
    "and even surpass, the original LLMâ€™s performance.\n",
    "Distilling step-by-step proposes a resource-efficient\n",
    "training-to-deployment paradigm compared to ex-\n",
    "isting methods. Further studies demonstrate the\n",
    "generalizability and the design choices made in\n",
    "Distilling step-by-step. Finally, we discuss the lim-\n",
    "itations, future directions and ethics statement of\n",
    "our work below.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01388862-bf36-4d62-9f30-14fd81ee0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are given a table extracted from a document, along with associated text from the same source. \\\n",
    "If the table is meaningful then summarize its content else mention 'no meaningful content'. \\\n",
    "Response should be in JSON format with schema {'summary': '...'}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "294d7095-1970-41db-84be-6f2fe22334e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_table1 = [\n",
    "    ['Independent\\nVariable', 'Dependent\\nVariable', 'Dependent\\nVariableType', 'Name'],\n",
    "    ['Many', 'Single', '2Categories', 'Binary classifi-\\ncation'],\n",
    "    ['Many', 'Single', '>2Categories', 'Multi-class\\nclassification'],\n",
    "    ['Many', 'Many', '2 Categories\\nper dependent\\nvariable', 'Multi-label\\nclassification'],\n",
    "    ['Many', 'Many', '> 2 Categories\\nper dependent\\nvariable', 'Multi-output\\nclassification'],\n",
    "    ['Single', 'Single', 'Numeric', 'Simple Regres-\\nsion'],\n",
    "    ['Many', 'Single', 'Numeric', 'Multiple\\nRegression'],\n",
    "    ['Many', 'Many', 'Numeric', 'Multivariate\\nMultiple\\nRegression']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b889f478-419c-466c-80f8-d4bb78fad023",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text1 = \"\"\"\n",
    "Reverse Principal Component Analysis for\\nMulti-Output Regression\\nAkshit Bhalla\\nDepartment of Industrial \\\n",
    "Engineering and Management\\nRV College of Engineering\\nBengaluru, Karnataka, \\\n",
    "India\\nakshitbhalla.im16@rvce.edu.in\\nAbstractâ€”The problem of multi-output regression deals with \\\n",
    "the methodology proposed in this paper significantly surpasses\\npredicting more than one value given \\\n",
    "an observation.This paper the performance of the most commonly adopted techniques. A\\nproposes a novel \\\n",
    "method to accomplish this task by using a simple 3 step procedure of transforming, predicting, and \\\n",
    "trans-\\npopular technique named Principal Component Analysis (PCA).\\nforming back proves to be excellent \\\n",
    "for making predictions,\\nThe approach is to reduce the dimensions \\\n",
    "of the target data\\nespecially when time is a concern.\\nand make predictions on it, following which the predictions \\\n",
    "are\\ntransformed to the higher dimension. This approach was com-\\nII. \\\n",
    "LITERATUREREVIEW\\npared against several existing approaches using publicly available\\ndatasets. It was found to largely \\\n",
    "outperform other approaches. The problem of multi-output regression is not new. It is\\nApplication areas include \\\n",
    "(not limited to) climatology, genetics, known by several names in literature including multi-target\\nimage processing \\\n",
    "and computer vision, and medicine.\\nregression, multi-response regression, and multivariate regres-\\nIndex \\\n",
    "Termsâ€”Principal Component Analysis, Multi-output\\nsion. The following table summarizes the many prediction\\nregression, \\\n",
    "Multivariate Regression, Machine Learning, Dimen-\\nsionality Reduction, Multivariate Statistics, Data Science tasks.\\nI. \\\n",
    "INTRODUCTION TABLEI\\nThe objective of multi-output regression is to predict more\\nCLASSIFICATION &REGRESSION PROBLEMS\\nthan \\\n",
    "one unknown dependent numeric variable when a few\\nindependent variables are known.There exist numerous appli- Independent \\\n",
    "Dependent Dependent Name\\nVariable Variable VariableType\\ncations for modeling and predicting several unknown variables\\nMany \\\n",
    "Single 2Categories Binary classifi-\\nsimultaneously. For example, predicting the coordinates and cation\\nvelocities of \\\n",
    "celestial objects, multi-trait prediction in genet- Many Single >2Categories Multi-class\\nclassification\\nics [1], \\\n",
    "forecasting temperature and pressure conditions in\\nMany Many 2 Categories Multi-label\\nclimatology, and prediction for \\\n",
    "gas tank levels [2]. For the per dependent classification\\nrecent COVID19 pandemic, John Hopkins University Center \\\n",
    "variable\\nMany Many > 2 Categories Multi-output\\nfor Systems Science and Engineering has been making data\\nper dependent \\\n",
    "classification\\navailable to the public [3]. Kaggle has been using this data variable\\nto host weekly research code \\\n",
    "competitions to predict the Single Single Numeric Simple Regres-\\ninfections and deaths for the following week [4]â€“[8]. \\\n",
    "This is sion\\nMany Single Numeric Multiple\\nalso a multi-output regression problem.\\nRegression\\nThe task of predicting \\\n",
    "multiple variables is interesting Many Many Numeric Multivariate\\nbecause more often than not,even the variables to predict share \\\n",
    "Multiple\\nRegression\\nsome relationship with each other. Ever since its introduction\\nby Karl Pearson in 1901, principal \\\n",
    "component analysis has\\nbecome the technique of choice for reducing dimensions.From In general, classification is the case when \\\n",
    "the dependent\\nbeing used in finance to reduce portfolio risk [9] to being variable is categorical and regression is the \\\n",
    "case when the\\nused in image processing and computer vision to empower dependent variable is numeric. Just for the sake \\\n",
    "of clarity,\\nautonomous cars [10], PCA has unlimited applications. The simple regression is the case when there is a single \\\n",
    "inde-\\nbeauty of this technique over other techniques for reducing pendent variable and a single numeric dependent \\\n",
    "variable\\ndimensions lies in the fact that it captures the essence of the to predict. Multiple regression is the case when \\\n",
    "there are\\ndata and allows one to decide what dimension to reduce to many independent variables and a single numeric \\\n",
    "dependent\\nand at how much loss of data. It might be counterintuitive to variabletopredict.Multivariate multiple \\\n",
    "regression is the case\\nsome, that a technique for reducing dimensions can be used when there are many independent variables \\\n",
    "and many numeric\\nfor modeling the multi-output regression problem. However, dependent variables to predict. For many \\\n",
    "decades several\\n978-1-7281-6453-3/20/$31.00Â©2020IEEE\\nAuthorized licensed use limited to: Columbia University Libraries. \\\n",
    "Downloaded on October 25,2024 at 03:56:04 UTC from IEEE Xplore. Restrictions apply.\\n49\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab261c6-3f1e-4b6f-b8cc-774022761600",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_summary1 = \"\"\"\n",
    "The table categorizes data types for classification and regression problems in machine learning. The categories are:\n",
    "\n",
    "* Binary classification (single dependent variable)\n",
    "* Multi-class classification (>2 categories per dependent variable)\n",
    "* Multi-label classification (2 categories per dependent variable)\n",
    "* Multi-output classification (> 2 categories per dependent variable)\n",
    "* Simple regression (1 independent variable, 1 numeric dependent variable)\n",
    "* Multiple regression (many independent variables, 1 numeric dependent variable)\n",
    "* Multivariate multiple regression (many independent variables, many numeric dependent variables)\n",
    "\n",
    "The text provides context on the problem of multi-output regression, which involves predicting more than one unknown \\\n",
    "dependent numeric variable when a few independent variables are known. It discusses how Principal Component Analysis \\\n",
    "(PCA) can be used to reduce dimensions and improve prediction accuracy. The paper proposes a novel method for multi-output \\\n",
    "regression using PCA and compares its performance against existing approaches.\n",
    "\n",
    "The text also mentions the various application areas of multi-output regression, including climatology, genetics, image \\\n",
    "processing, and computer vision, as well as medicine. It highlights the importance of dimensionality reduction in machine \\\n",
    "learning problems and provides an overview of the key concepts and techniques used in classification and regression problems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9cda337-a747-4cd9-b32f-f61515fa555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_table2 = [\n",
    "    ['Observed\\nPrediction'], \n",
    "    ['gpt-4']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5106a58-290b-4146-9441-ad52ebed7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text2 = \"\"\"\n",
    "OpenAI code base next word prediction \\nBits per word\\n6.0\\n Observed\\n Prediction\\n 5.0 gpt-4\\n4.0\\n3.0\\n2.0\\n1.0\\n100p \\\n",
    "10n 1Âµ 100Âµ 0.01 1\\nCompute\\nFigure1. Performance of GPT-4 and smaller models. The metric is final loss on a dataset \\\n",
    "derived\\nfrom our internal code base.This is a convenient, large dataset of code tokens which is not contained in\\n the \\\n",
    "training set. We chose to look at loss because it tends to be less noisy than other measures across\\ndifferent amounts of \\\n",
    "training compute. A power law fit to the smaller models(excludingGPT-4) is\\nshown as the dotted line; this fit accurately \\\n",
    "predicts GPT-4â€™s final loss.The x-axis is training compute\\n normalized so that GPT-4 is 1.\\nCapability prediction on 23 \\\n",
    "coding problems\\nâ€“Mean Log Pass Rate\\n5\\n Observed\\nPrediction\\n4 gpt-4\\n3\\n2\\n1\\n0\\n1Âµ 10Âµ 100Âµ 0.001 0.01 0.1 \\\n",
    "1\\nCompute\\nFigure2.Performance of GPT-4 and smaller models.The metric is mean log pass rate on a subsetof\\n the Human Eval \\\n",
    "dataset. A power law fit to the smaller models (excluding GPT-4) is shown as the dotted\\nline; this fit accurately predicts \\\n",
    "GPT-4â€™s performance.The x-axis is training compute normalized so that\\nGPT-4 is 1.\\n3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40ac670-ff26-4544-9ea6-fd2de66430dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_summary2 = \"no meaningful content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "632d30e1-6cbf-489b-802e-6cbbd15aba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"\n",
    "# Table: \n",
    "# ```\n",
    "# {example_table1}\n",
    "# ```\n",
    "\n",
    "# Text:\n",
    "# ```\n",
    "# {example_text1}\n",
    "# ```\n",
    "\n",
    "# Summary:\n",
    "# {{\n",
    "#     'summary': '{example_summary1}'\n",
    "# }}\n",
    "\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Table: \n",
    "# ```\n",
    "# {example_table2}\n",
    "# ```\n",
    "\n",
    "# Text:\n",
    "# ```\n",
    "# {example_text2}\n",
    "# ```\n",
    "\n",
    "# Summary:\n",
    "# {{\n",
    "#     'summary': '{example_summary2}'\n",
    "# }}\n",
    "\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Table:\n",
    "# ```\n",
    "# {table}\n",
    "# ```\n",
    "\n",
    "# Text:\n",
    "# ```\n",
    "# {text}\n",
    "# ```\n",
    "\n",
    "# Summary:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19ee676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "Table:\n",
    "```\n",
    "{table}\n",
    "```\n",
    "\n",
    "Text:\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\n",
    "Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75ad8f90-53a3-4dc5-9069-2fc56ea5f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = query_ollama(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0db7fe40-165f-4dce-a338-529bd84bb558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"summary\": \"The table shows that Distilling step-by-step improves performance on various tasks when using different sizes of LLMs as input for extracting rationales. It outperforms standard finetuning in some cases, especially with smaller LLMs like the 20B GPT-NeoX model. Multi-task training is also more effective than single-task rationale and label joint prediction.\"}\n"
     ]
    }
   ],
   "source": [
    "print(res[\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
